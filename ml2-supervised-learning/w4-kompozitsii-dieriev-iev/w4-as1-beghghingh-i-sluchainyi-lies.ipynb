{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание: Бэггинг и случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "# from sklearn.datasets import load_digits\n",
    "from sklearn import cross_validation, datasets, tree, ensemble #, metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "from lib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd240e0c0f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfcAAAH+CAYAAACBekfvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wex1bhK6r78qwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd240e0c470>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 255,
       "width": 251
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray() \n",
    "plt.matshow(digits.images[0]) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества далее нужно будет использовать cross_val_score из sklearn.cross_validation с параметром cv=10. Эта функция реализует k-fold cross validation c k равным значению параметра cv. Мы предлагаем использовать k=10, чтобы полученные оценки качества имели небольшой разброс, и было проще проверить полученные ответы. На практике же часто хватает и k=5. Функция cross_val_score будет возвращать numpy.ndarray, в котором будет k чисел - качество в каждом из k экспериментов k-fold cross validation. Для получения среднего значения (которое и будет оценкой качества работы) вызовите метод .mean() у массива, который возвращает cross_val_score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте DecisionTreeClassifier с настройками по умолчанию и измерьте качество его работы с помощью cross_val_score. Эта величина и будет ответом в пункте 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 290 ms, sys: 0 ns, total: 290 ms\n",
      "Wall time: 283 ms\n"
     ]
    }
   ],
   "source": [
    "%time cvs = cross_validation.cross_val_score(clf, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w4-as1-1=\"0.830333723474\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pf('w4-as1-1', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Воспользуйтесь BaggingClassifier из sklearn.ensemble, чтобы обучить бэггинг над DecisionTreeClassifier. Используйте в BaggingClassifier параметры по умолчанию, задав только количество деревьев равным 100.\n",
    "\n",
    "Качество классификации новой модели - ответ в пункте 2. Обратите внимание, как соотносится качество работы композиции решающих деревьев с качеством работы одного решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 0 ns, total: 13.1 s\n",
      "Wall time: 13.2 s\n",
      "w4-as1-2=\"0.924313692083\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.BaggingClassifier(n_estimators=100, random_state=0)\n",
    "%time cvs = cross_validation.cross_val_score(clf, X, y, cv=10)\n",
    "pf('w4-as1-2', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь изучите параметры BaggingClassifier и выберите их такими, чтобы каждый базовый алгоритм обучался не на всех d признаках, а на d‾‾√ случайных признаков. Качество работы получившегося классификатора - ответ в пункте 3. Корень из числа признаков - часто используемая эвристика в задачах классификации, в задачах регрессии же часто берут число признаков, деленное на три. Но в общем случае ничто не мешает вам выбирать любое другое число случайных признаков.m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.71 s, sys: 50 ms, total: 3.76 s\n",
      "Wall time: 3.77 s\n",
      "w4-as1-3=\"0.937159275448\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_features = int(X.shape[1] ** 0.5)\n",
    "# max_features\n",
    "clf = ensemble.BaggingClassifier(n_estimators=100, random_state=0, max_features=max_features)\n",
    "%time cvs = cross_validation.cross_val_score(clf, X, y, cv=10)\n",
    "pf('w4-as1-3', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, давайте попробуем выбирать случайные признаки не один раз на все дерево, а при построении каждой вершины дерева. Сделать это несложно: нужно убрать выбор случайного подмножества признаков в BaggingClassifier и добавить его в DecisionTreeClassifier. Какой параметр за это отвечает, можно понять из документации sklearn, либо просто попробовать угадать (скорее всего, у вас сразу получится). Попробуйте выбирать опять же d‾‾√ признаков. Качество полученного классификатора на контрольной выборке и будет ответом в пункте 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.76 s, sys: 70 ms, total: 3.83 s\n",
      "Wall time: 3.99 s\n",
      "w4-as1-4=\"0.954477362317\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_features = int(X.shape[1] ** 0.5)\n",
    "# max_features\n",
    "est = tree.DecisionTreeClassifier(random_state=0, max_features=max_features)\n",
    "clf = ensemble.BaggingClassifier(est, n_estimators=100, random_state=0)\n",
    "%time cvs = cross_validation.cross_val_score(clf, X, y, cv=10)\n",
    "pf('w4-as1-4', cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученный в пункте 4 классификатор - бэггинг на рандомизированных деревьях (в которых при построении каждой вершины выбирается случайное подмножество признаков и разбиение ищется только по ним). Это в точности соответствует алгоритму Random Forest, поэтому почему бы не сравнить качество работы классификатора с RandomForestClassifier из sklearn.ensemble. Сделайте это, а затем изучите, как качество классификации на данном датасете зависит от количества деревьев, количества признаков, выбираемых при построении каждой вершины дерева, а также ограничений на глубину дерева. Для наглядности лучше построить графики зависимости качества от значений параметров, но для сдачи задания это делать не обязательно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе наблюдений выпишите через пробел номера правильных утверждений из приведенных ниже в порядке возрастания номера (это будет ответ в п.5)\n",
    "\n",
    "1) Случайный лес сильно переобучается с ростом количества деревьев\n",
    "\n",
    "2) При очень маленьком числе деревьев (5, 10, 15), случайный лес работает хуже, чем при большем числе деревьев\n",
    "\n",
    "3) С ростом количества деревьев в случайном лесе, в какой-то момент деревьев становится достаточно для высокого качества классификации, а затем качество существенно не меняется.\n",
    "\n",
    "4) При большом количестве признаков (для данного датасета - 40, 50) качество классификации становится хуже, чем при малом количестве признаков (5, 10). Это связано с тем, что чем меньше признаков выбирается в каждом узле, тем более различными получаются деревья (ведь деревья сильно неустойчивы к изменениям в обучающей выборке), и тем лучше работает их композиция.\n",
    "\n",
    "5) При большом количестве признаков (40, 50, 60) качество классификации лучше, чем при малом количестве признаков (5, 10). Это связано с тем, что чем больше признаков - тем больше информации об объектах, а значит алгоритм может делать прогнозы более точно.\n",
    "\n",
    "6) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса намного лучше, чем без ограничения глубины, т.к. деревья получаются не переобученными. С ростом глубины деревьев качество ухудшается.\n",
    "\n",
    "7) При небольшой максимальной глубине деревьев (5-6) качество работы случайного леса заметно хуже, чем без ограничений, т.к. деревья получаются недообученными. С ростом глубины качество сначала улучшается, а затем не меняется существенно, т.к. из-за усреднения прогнозов и различий деревьев их переобученность в бэггинге не сказывается на итоговом качестве (все деревья преобучены по-разному, и при усреднении они компенсируют переобученность друг-друга)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w4-as1-5=\"2 3 4 7\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pf('w4-as1-5', \"2 3 4 7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
